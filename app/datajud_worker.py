#!/usr/bin/env python3
"""
================================================================================
WORKER DE MONITORAMENTO AUTOM√ÅTICO VIA DATAJUD - JurisPocket
================================================================================

Este m√≥dulo implementa um rob√¥ inteligente que consulta a API p√∫blica Datajud
do CNJ (Conselho Nacional de Justi√ßa) e atualiza automaticamente o banco de 
dados MySQL/SQLite com novas movimenta√ß√µes de processos cadastrados.

FUNCIONAMENTO:
- Executa 2 vezes ao dia: 08:00 e 17:30 (hor√°rios configur√°veis)
- Roda de forma ass√≠ncrona sem travar a aplica√ß√£o principal
- Consulta apenas processos marcados para monitoramento
- Evita duplicatas com chave √∫nica (processo_id, codigo_movimento, data_movimento)
- Cria notifica√ß√µes inteligentes para o usu√°rio
- Registra logs detalhados de cada consulta

CONFIGURA√á√ÉO NECESS√ÅRIA:
1. Defina sua API Key do Datajud (https://datajud.cnj.jus.br)
   - Vari√°vel de ambiente: DATAJUD_API_KEY
   - Ou edite a constante DATAJUD_API_KEY neste arquivo (n√£o recomendado para produ√ß√£o)
   
2. Configure os hor√°rios de execu√ß√£o na fun√ß√£o schedule_datajud_monitoring()
   em app.py (linhas 800-810)

3. Certifique-se de ter o Python 3.7+ e as depend√™ncias instaladas:
   pip install -r requirements.txt

ESTRUTURA DE DADOS:
- Tabelas utilizadas:
  ‚úì processos - Armazena os processos
  ‚úì processo_monitor_config - Config de monitoramento por processo
  ‚úì movimentacoes_processo - Historicamente de movimenta√ß√µes (CHAVE √öNICA!)
  ‚úì alertas_notificacoes - Notifica√ß√µes para o usu√°rio
  ‚úì datajud_consulta_logs - Logs de todas as consultas feitas
  
SEGURAN√áA:
- API Key deve estar em vari√°vel de ambiente (NUNCA em c√≥digo)
- Rate limiting autom√°tico para respeitar TOS da API Datajud
- Timeout configur√°vel para n√£o congelar a aplica√ß√£o
- Tratamento robusto de erros com logging
================================================================================
"""

import os
import json
import time
import sqlite3
import requests
from datetime import datetime, timedelta
from typing import Dict, List, Any, Optional, Tuple
import logging

# ============================================================================
# CONFIGURA√á√ÉO DE LOGGING
# ============================================================================

# Cria diret√≥rio de logs se n√£o existir
LOG_DIR = os.path.join(os.path.dirname(__file__), 'logs')
os.makedirs(LOG_DIR, exist_ok=True)

# Configura logger
logger = logging.getLogger(__name__)
logger.setLevel(logging.DEBUG)

# Handler para arquivo
fh = logging.FileHandler(os.path.join(LOG_DIR, 'datajud_worker.log'))
fh.setLevel(logging.DEBUG)

# Handler para console
ch = logging.StreamHandler()
ch.setLevel(logging.INFO)

# Formato
formatter = logging.Formatter(
    '%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    datefmt='%d/%m/%Y %H:%M:%S'
)
fh.setFormatter(formatter)
ch.setFormatter(formatter)

logger.addHandler(fh)
logger.addHandler(ch)

# ============================================================================
# CONFIGURA√á√ïES
# ============================================================================

# üîë CONFIGURA√á√ÉO DA API DATAJUD
# Obtenha sua chave em: https://datajud.cnj.jus.br/portal/externo/consultar-api
DATAJUD_API_KEY = os.environ.get('DATAJUD_API_KEY', '')

# URL base da API p√∫blica Datajud
DATAJUD_BASE_URL = 'https://api-publica.datajud.cnj.jus.br'

# Timeout para requisi√ß√µes HTTP (em segundos)
DATAJUD_TIMEOUT = 30

# Delay entre requisi√ß√µes para respeitar rate limiting (em segundos)
DATAJUD_DELAY_ENTRE_REQUISICOES = 2

# Caminho do banco de dados SQLite
DB_PATH = os.path.join(os.path.dirname(__file__), 'jurispocket.db')

# ============================================================================
# ROTEADOR DE TRIBUNAIS DATAJUD
# ============================================================================
# Este dicion√°rio mapeia a sigla do tribunal para o endpoint espec√≠fico da API
# A URL final fica: {BASE_URL}{ENDPOINT}

TRIBUNAIS_ENDPOINTS = {
    # Tribunais Superiores
    'TST': '/api_publica_tst/_search',
    'STJ': '/api_publica_stj/_search',
    'TSE': '/api_publica_tse/_search',
    'STM': '/api_publica_stm/_search',
    
    # Tribunais Regionais Federais
    'TRF1': '/api_publica_trf1/_search',
    'TRF2': '/api_publica_trf2/_search',
    'TRF3': '/api_publica_trf3/_search',
    'TRF4': '/api_publica_trf4/_search',
    'TRF5': '/api_publica_trf5/_search',
    'TRF6': '/api_publica_trf6/_search',
    
    # Tribunais de Justi√ßa Estaduais
    'TJSP': '/api_publica_tjsp/_search',
    'TJRJ': '/api_publica_tjrj/_search',
    'TJMG': '/api_publica_tjmg/_search',
    'TJRS': '/api_publica_tjrs/_search',
    'TJPR': '/api_publica_tjpr/_search',
    'TJSC': '/api_publica_tjsc/_search',
    'TJBA': '/api_publica_tjba/_search',
    'TJGO': '/api_publica_tjgo/_search',
    'TJPE': '/api_publica_tjpe/_search',
    'TJCE': '/api_publica_tjce/_search',
    'TJPA': '/api_publica_tjpa/_search',
    'TJAM': '/api_publica_tjam/_search',
    'TJRO': '/api_publica_tjro/_search',
    'TJAC': '/api_publica_tjac/_search',
    'TJAP': '/api_publica_tjap/_search',
    'TJRR': '/api_publica_tjrr/_search',
    'TJTO': '/api_publica_tjto/_search',
    'TJMS': '/api_publica_tjms/_search',
    'TJMT': '/api_publica_tjmt/_search',
    'TJDF': '/api_publica_tjdft/_search',
    'TJES': '/api_publica_tjes/_search',
    'TJPB': '/api_publica_tjpb/_search',
    'TJRN': '/api_publica_tjrn/_search',
    'TJAL': '/api_publica_tjal/_search',
    'TJSE': '/api_publica_tjse/_search',
    'TJMA': '/api_publica_tjma/_search',
    'TJPI': '/api_publica_tjpi/_search',
    
    # Tribunais Regionais do Trabalho
    'TRT1': '/api_publica_trt1/_search',
    'TRT2': '/api_publica_trt2/_search',
    'TRT3': '/api_publica_trt3/_search',
    'TRT4': '/api_publica_trt4/_search',
    'TRT5': '/api_publica_trt5/_search',
    'TRT6': '/api_publica_trt6/_search',
    'TRT7': '/api_publica_trt7/_search',
    'TRT8': '/api_publica_trt8/_search',
    'TRT9': '/api_publica_trt9/_search',
    'TRT10': '/api_publica_trt10/_search',
    'TRT11': '/api_publica_trt11/_search',
    'TRT12': '/api_publica_trt12/_search',
    'TRT13': '/api_publica_trt13/_search',
    'TRT14': '/api_publica_trt14/_search',
    'TRT15': '/api_publica_trt15/_search',
    'TRT16': '/api_publica_trt16/_search',
    'TRT17': '/api_publica_trt17/_search',
    'TRT18': '/api_publica_trt18/_search',
    'TRT19': '/api_publica_trt19/_search',
    'TRT20': '/api_publica_trt20/_search',
    'TRT21': '/api_publica_trt21/_search',
    'TRT22': '/api_publica_trt22/_search',
    'TRT23': '/api_publica_trt23/_search',
    'TRT24': '/api_publica_trt24/_search',
}

# ============================================================================
# MAPEAMENTO COMPLETO DO NPU (Novo Padr√£o CNJ)
# Estrutura: NNNNNNN-DD.AAAA.J.TR.OOOO
# J = Justi√ßa (1 d√≠gito), TR = Tribunal/Regi√£o (2 d√≠gitos)
# C√≥digo = J + TR (3 d√≠gitos, √≠ndices 13:16)
# ============================================================================

CODIGO_ORGAO_MAP = {
    # 1. TRIBUNAIS SUPERIORES (TR = 00)
    '300': 'STJ',  # Superior Tribunal de Justi√ßa (J=3)
    '500': 'TST',  # Tribunal Superior do Trabalho (J=5)
    '600': 'TSE',  # Tribunal Superior Eleitoral (J=6)
    '700': 'STM',  # Superior Tribunal Militar (J=7)
    
    # 2. JUSTI√áA FEDERAL (J = 4) - TRF1 a TRF6
    '401': 'TRF1', '402': 'TRF2', '403': 'TRF3',
    '404': 'TRF4', '405': 'TRF5', '406': 'TRF6',
    
    # 3. JUSTI√áA DO TRABALHO (J = 5) - TRT1 a TRT24
    '501': 'TRT1',   '502': 'TRT2',   '503': 'TRT3',   '504': 'TRT4',
    '505': 'TRT5',   '506': 'TRT6',   '507': 'TRT7',   '508': 'TRT8',
    '509': 'TRT9',   '510': 'TRT10',  '511': 'TRT11',  '512': 'TRT12',
    '513': 'TRT13',  '514': 'TRT14',  '515': 'TRT15',  '516': 'TRT16',
    '517': 'TRT17',  '518': 'TRT18',  '519': 'TRT19',  '520': 'TRT20',
    '521': 'TRT21',  '522': 'TRT22',  '523': 'TRT23',  '524': 'TRT24',
    
    # 4. JUSTI√áA ELEITORAL (J = 6) - TREs dos estados
    '601': 'TRE-AC', '602': 'TRE-AL', '603': 'TRE-AM', '604': 'TRE-AP',
    '605': 'TRE-BA', '606': 'TRE-CE', '607': 'TRE-DF', '608': 'TRE-ES',
    '609': 'TRE-GO', '610': 'TRE-MA', '611': 'TRE-MT', '612': 'TRE-MS',
    '613': 'TRE-MG', '614': 'TRE-PA', '615': 'TRE-PB', '616': 'TRE-PR',
    '617': 'TRE-PE', '618': 'TRE-PI', '619': 'TRE-RJ', '620': 'TRE-RN',
    '621': 'TRE-RS', '622': 'TRE-RO', '623': 'TRE-RR', '624': 'TRE-SC',
    '625': 'TRE-SE', '626': 'TRE-SP', '627': 'TRE-TO',
    
    # 5. JUSTI√áA ESTADUAL (J = 8) - TJs (ordem alfab√©tica dos estados)
    '801': 'TJAC',  # Acre
    '802': 'TJAL',  # Alagoas
    '803': 'TJAM',  # Amazonas
    '804': 'TJAP',  # Amap√°
    '805': 'TJBA',  # Bahia
    '806': 'TJCE',  # Cear√°
    '807': 'TJDF',  # Distrito Federal
    '808': 'TJES',  # Esp√≠rito Santo
    '809': 'TJGO',  # Goi√°s
    '810': 'TJMA',  # Maranh√£o
    '811': 'TJMT',  # Mato Grosso
    '812': 'TJMS',  # Mato Grosso do Sul
    '813': 'TJMG',  # Minas Gerais
    '814': 'TJPA',  # Par√°
    '815': 'TJPB',  # Para√≠ba
    '816': 'TJPR',  # Paran√°
    '817': 'TJPE',  # Pernambuco
    '818': 'TJPI',  # Piau√≠
    '819': 'TJRJ',  # Rio de Janeiro
    '820': 'TJRN',  # Rio Grande do Norte
    '821': 'TJRS',  # Rio Grande do Sul
    '822': 'TJRO',  # Rond√¥nia
    '823': 'TJRR',  # Roraima
    '824': 'TJSC',  # Santa Catarina
    '825': 'TJSE',  # Sergipe
    '826': 'TJSP',  # S√£o Paulo
    '827': 'TJTO',  # Tocantins
    
    # 6. JUSTI√áA MILITAR ESTADUAL (J = 9)
    '913': 'TJMMG',  # Minas Gerais
    '921': 'TJMRS',  # Rio Grande do Sul
    '926': 'TJMSP',  # S√£o Paulo
}

# ============================================================================
# FUN√á√ïES UTILIT√ÅRIAS
# ============================================================================


def get_db_connection() -> sqlite3.Connection:
    """
    Estabelece conex√£o com o banco de dados SQLite
    
    Returns:
        Conex√£o SQLite com row_factory configurado
    """
    conn = sqlite3.connect(DB_PATH)
    conn.row_factory = sqlite3.Row
    return conn


def extrair_tribunal_do_npu(numero_processo: str) -> Optional[str]:
    """
    Extrai a sigla do tribunal a partir do n√∫mero do processo (NPU)
    
    ‚ÑπÔ∏è NPU: N√∫mero √∫nico de processo com 20 d√≠gitos
    Estrutura: NNNNNNN-DD.AAAA.J.TR.OOOO
    - J (Justi√ßa): 1 d√≠gito (√≠ndice 13)
    - TR (Tribunal/Regi√£o): 2 d√≠gitos (√≠ndices 14-15)
    - C√≥digo = J + TR (3 d√≠gitos)
    
    Args:
        numero_processo: String com o n√∫mero (com ou sem formata√ß√£o)
        
    Returns:
        Sigla do tribunal (ex: 'TJSP', 'TRF1') ou None se inv√°lido
        
    Exemplo:
        >>> extrair_tribunal_do_npu("0000001-23.2024.8.26.0100")
        'TJSP'  # J=8, TR=26, C√≥digo=826
    """
    import re
    
    # Remove tudo que n√£o √© n√∫mero
    limpo = re.sub(r'[^0-9]', '', numero_processo)
    
    # Deve ter exatamente 20 d√≠gitos
    if len(limpo) != 20:
        logger.warning(f"NPU inv√°lido (comprimento {len(limpo)}): {numero_processo}")
        return None
    
    # Extrai J (1 d√≠gito) e TR (2 d√≠gitos)
    j = limpo[13]          # Justi√ßa (1 d√≠gito)
    tr = limpo[14:16]      # Tribunal/Regi√£o (2 d√≠gitos)
    codigo_orgao = j + tr  # C√≥digo completo (3 d√≠gitos)
    
    tribunal = CODIGO_ORGAO_MAP.get(codigo_orgao)
    
    if not tribunal:
        logger.warning(f"C√≥digo de √≥rg√£o desconhecido: {codigo_orgao} (J={j}, TR={tr}) em {numero_processo}")
        return None
    
    return tribunal


def consultar_processo_datajud(
    numero_processo: str,
    tribunal_sigla: str
) -> Dict[str, Any]:
    """
    Consulta um processo na API p√∫blica Datajud do CNJ
    
    üì° DETALHES DA REQUISI√á√ÉO:
    - M√©todo: POST
    - URL: {DATAJUD_BASE_URL}{TRIBUNAIS_ENDPOINTS[tribunal_sigla]}
    - Headers:
        - Authorization: ApiKey {DATAJUD_API_KEY}
        - Content-Type: application/json
    - Body: {"query": {"match": {"numeroProcesso": "NUMERO_LIMPO"}}}
    
    üì® RESPOSTA: Formato Elasticsearch
    - JSON com estrutura: hits.hits[0]._source
    - Cont√©m: numeroProcesso, dataAjuizamento, classe, orgaoJulgador, movimentos
    
    Args:
        numero_processo: NPU do processo
        tribunal_sigla: Sigla identificada do tribunal
        
    Returns:
        Dict com:
        - sucesso: bool
        - encontrado: bool (if sucesso=True)
        - error: str (if sucesso=False)
        - tribunal: str
        - numero_processo: str
        - data_ajuizamento: str
        - classe: {codigo, nome}
        - orgao_julgador: {nome}
        - movimentos: List[{codigo, nome, data_hora, complementos}]
        - tempo_resposta_ms: int
    """
    
    # ========================================================================
    # VALIDA√á√ÉO PR√â-REQUISI√á√ÉO
    # ========================================================================
    
    if not DATAJUD_API_KEY:
        erro_msg = (
            "‚ùå API Key n√£o configurada!\n"
            "Configure a vari√°vel de ambiente DATAJUD_API_KEY\n"
            "Obtenha a chave em: https://datajud.cnj.jus.br/portal/externo/consultar-api"
        )
        logger.error(erro_msg)
        return {
            'sucesso': False,
            'erro': erro_msg,
            'tribunal': tribunal_sigla
        }
    
    endpoint = TRIBUNAIS_ENDPOINTS.get(tribunal_sigla)
    if not endpoint:
        return {
            'sucesso': False,
            'erro': f'Tribunal {tribunal_sigla} n√£o mapeado',
            'tribunal': tribunal_sigla
        }
    
    # ========================================================================
    # CONSTRU√á√ÉO DA REQUISI√á√ÉO
    # ========================================================================
    
    import re
    numero_limpo = re.sub(r'[^0-9]', '', numero_processo)
    
    url = f"{DATAJUD_BASE_URL}{endpoint}"
    
    headers = {
        'Authorization': f'ApiKey {DATAJUD_API_KEY}',
        'Content-Type': 'application/json'
    }
    
    # Query em formato Elasticsearch: busca pelo n√∫mero exato
    payload = {
        "query": {
            "match": {
                "numeroProcesso": numero_limpo
            }
        }
    }
    
    # ========================================================================
    # EXECU√á√ÉO DA REQUISI√á√ÉO
    # ========================================================================
    
    inicio = time.time()
    
    try:
        logger.info(f"üîç Consultando {tribunal_sigla}: {numero_limpo}")
        
        response = requests.post(
            url,
            headers=headers,
            json=payload,
            timeout=DATAJUD_TIMEOUT
        )
        
        tempo_ms = int((time.time() - inicio) * 1000)
        
        # Status HTTP n√£o 200
        if response.status_code != 200:
            erro = f"HTTP {response.status_code}"
            logger.warning(f"‚ùå Erro na API Datajud: {erro} ({tempo_ms}ms)")
            return {
                'sucesso': False,
                'erro': erro,
                'tribunal': tribunal_sigla,
                'tempo_resposta_ms': tempo_ms,
                'status_code': response.status_code
            }
        
        # ====================================================================
        # PARSER DA RESPOSTA ELASTICSEARCH
        # ====================================================================
        
        data = response.json()
        
        hits = data.get('hits', {}).get('hits', [])
        
        # Processo n√£o encontrado
        if not hits:
            logger.info(f"‚ö†Ô∏è  Processo n√£o encontrado: {numero_limpo} em {tribunal_sigla}")
            return {
                'sucesso': True,
                'encontrado': False,
                'tribunal': tribunal_sigla,
                'mensagem': 'Processo ainda n√£o est√° dispon√≠vel na API',
                'tempo_resposta_ms': tempo_ms
            }
        
        # Extrai dados do primeiro hit (OpenSearch retorna ordenado por relev√¢ncia)
        source = hits[0].get('_source', {})
        
        # ====================================================================
        # EXTRA√á√ÉO E MAPEAMENTO DE DADOS
        # ====================================================================
        
        # Movimenta√ß√µes (hist√≥rico)
        movimentos_raw = source.get('movimentos', [])
        movimentos = []
        
        for mov in movimentos_raw:
            movimentos.append({
                'codigo': mov.get('codigo'),
                'nome': mov.get('nome'),
                'data_hora': mov.get('dataHora'),
                'complementos': mov.get('complementosTabelados', [])
            })
        
        # Ordena por data decrescente (mais recente primeiro)
        movimentos.sort(key=lambda x: x.get('data_hora', ''), reverse=True)
        
        logger.info(f"‚úÖ {len(movimentos)} movimenta√ß√µes encontradas em {tempo_ms}ms")
        
        return {
            'sucesso': True,
            'encontrado': True,
            'tribunal': tribunal_sigla,
            'numero_processo': source.get('numeroProcesso'),
            'data_ajuizamento': source.get('dataAjuizamento'),
            'classe': {
                'codigo': source.get('classe', {}).get('codigo'),
                'nome': source.get('classe', {}).get('nome')
            },
            'orgao_julgador': {
                'nome': source.get('orgaoJulgador', {}).get('nome')
            },
            'movimentos': movimentos,
            'tiempo_resposta_ms': tempo_ms
        }
    
    except requests.exceptions.Timeout:
        tempo_ms = int((time.time() - inicio) * 1000)
        msg = f"Timeout ap√≥s {DATAJUD_TIMEOUT}s"
        logger.error(f"‚è±Ô∏è  {msg} no tribunal {tribunal_sigla}")
        return {
            'sucesso': False,
            'erro': msg,
            'tribunal': tribunal_sigla,
            'tempo_resposta_ms': tempo_ms
        }
    
    except requests.exceptions.RequestException as e:
        tempo_ms = int((time.time() - inicio) * 1000)
        logger.error(f"üåê Erro de conex√£o: {str(e)}")
        return {
            'sucesso': False,
            'erro': f'Erro de conex√£o: {str(e)}',
            'tribunal': tribunal_sigla,
            'tempo_resposta_ms': tempo_ms
        }
    
    except json.JSONDecodeError as e:
        tempo_ms = int((time.time() - inicio) * 1000)
        logger.error(f"üìÑ Erro ao decodificar JSON: {str(e)}")
        return {
            'sucesso': False,
            'erro': 'Resposta inv√°lida da API',
            'tribunal': tribunal_sigla,
            'tempo_resposta_ms': tempo_ms
        }
    
    except Exception as e:
        tempo_ms = int((time.time() - inicio) * 1000)
        logger.exception(f"‚ùå Erro inesperado: {str(e)}")
        return {
            'sucesso': False,
            'erro': str(e),
            'tribunal': tribunal_sigla,
            'tempo_resposta_ms': tempo_ms
        }


def salvar_movimentacoes(
    conn: sqlite3.Connection,
    processo_id: int,
    workspace_id: int,
    movimentos: List[Dict]
) -> Tuple[int, int, List[Dict]]:
    """
    Salva movimenta√ß√µes no banco de dados com prote√ß√£o contra duplicatas
    
    üîê CHAVE √öNICA: (processo_id, codigo_movimento, data_movimento)
    - SQLite usa INSERT OR IGNORE para pular duplicatas
    - Garante que a mesma movimenta√ß√£o nunca seja inserida 2x
    
    ‚ö° OPERA√á√ÉO:
    1. Para cada movimenta√ß√£o, tenta inserir
    2. Se violar UNIQUE constraint, ignora (duplicata)
    3. Se inserir, incrementa contador de novas
    4. Retorna tupla: (inseridas, duplicadas, novas_movimentacoes)
    
    Args:
        conn: Conex√£o com banco de dados
        processo_id: ID do processo
        workspace_id: ID do workspace
        movimentos: Lista de movimenta√ß√µes da API
        
    Returns:
        Tuple (inseridas, duplicadas, lista_de_novas_movimentacoes)
    """
    
    cursor = conn.cursor()
    inseridas = 0
    duplicadas = 0
    novas_movimentacoes = []
    
    try:
        for mov in movimentos:
            codigo = mov.get('codigo')
            nome = mov.get('nome', 'Movimenta√ß√£o sem descri√ß√£o')
            data_hora = mov.get('data_hora')
            complementos_list = mov.get('complementos', [])
            
            # ================================================================
            # CONVERS√ÉO DE DATA: ISO 8601 ‚Üí DATETIME MySQL
            # ================================================================
            # A API retorna em ISO 8601 (exemplo: 2024-02-21T15:30:00Z)
            # Converte para: YYYY-MM-DD HH:MM:SS
            
            if data_hora:
                try:
                    # Remove 'Z' (UTC indicator) e converte
                    data_clean = data_hora.replace('Z', '+00:00')
                    # Python 3.7+: fromisoformat com timezone
                    from datetime import datetime as dt_cls
                    dt = dt_cls.fromisoformat(data_clean)
                    data_movimento = dt.strftime('%Y-%m-%d %H:%M:%S')
                except (ValueError, AttributeError):
                    # Fallback: usa como est√°
                    data_movimento = data_hora[:19]  # Toma os 19 primeiros chars
            else:
                data_movimento = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
            
            # Salva complementos como JSON string
            complementos_json = json.dumps(complementos_list, ensure_ascii=False)
            
            # ================================================================
            # INSERT OR IGNORE
            # ================================================================
            # Se a combina√ß√£o (processo_id, codigo_movimento, data_movimento)
            # j√° existir, ser√° ignorado (rowcount = 0)
            # Se for novo, ser√° inserido (rowcount = 1)
            
            cursor.execute('''
                INSERT OR IGNORE INTO movimentacoes_processo 
                (workspace_id, processo_id, codigo_movimento, nome_movimento,
                 data_movimento, complementos, fonte, created_at)
                VALUES (?, ?, ?, ?, ?, ?, ?, ?)
            ''', (
                workspace_id,
                processo_id,
                codigo,
                nome,
                data_movimento,
                complementos_json,
                'datajud',
                datetime.now().strftime('%Y-%m-%d %H:%M:%S')
            ))
            
            if cursor.rowcount > 0:
                inseridas += 1
                novas_movimentacoes.append({
                    'codigo': codigo,
                    'nome': nome,
                    'data': data_movimento
                })
            else:
                duplicadas += 1
        
        conn.commit()
        logger.info(f"üíæ Salvo: {inseridas} novas, {duplicadas} duplicadas")
        
    except Exception as e:
        conn.rollback()
        logger.error(f"‚ùå Erro ao salvar movimenta√ß√µes: {e}")
    
    return inseridas, duplicadas, novas_movimentacoes


def criar_alertas(
    conn: sqlite3.Connection,
    processo_id: int,
    workspace_id: int,
    numero_processo: str,
    novas_movimentacoes: List[Dict]
) -> int:
    """
    Cria alertas/notifica√ß√µes para novas movimenta√ß√µes
    
    üí° L√ìGICA:
    - Para cada movimenta√ß√£o nova, cria um alerta
    - Alerta fica com lido=FALSE para aparecer como "novo"
    - O usu√°rio ver√° assim que fazer login ou abrir dashboard
    - Pode marcar como lido pela API
    
    Args:
        conn: Conex√£o com banco
        processo_id: ID do processo
        workspace_id: ID do workspace
        numero_processo: NPU para exibir
        novas_movimentacoes: Lista de novas movimenta√ß√µes
        
    Returns:
        Quantidade de alertas criados
    """
    
    cursor = conn.cursor()
    alertas_criados = 0
    
    try:
        for mov in novas_movimentacoes:
            # Extrai apenas os √∫ltimos 9 d√≠gitos do NPU para exibir no alerta
            npu_curto = numero_processo[-9:] if len(numero_processo) >= 9 else numero_processo
            
            titulo = f"üîî Nova movimenta√ß√£o - {npu_curto}"
            mensagem = f"{mov['nome']}\nData: {mov['data']}"
            
            cursor.execute('''
                INSERT INTO alertas_notificacoes
                (workspace_id, processo_id, tipo, titulo, mensagem, lido, data_criacao)
                VALUES (?, ?, ?, ?, ?, ?, ?)
            ''', (
                workspace_id,
                processo_id,
                'movimentacao',
                titulo,
                mensagem,
                False,  # Novo alerta n√£o lido
                datetime.now().strftime('%Y-%m-%d %H:%M:%S')
            ))
            
            alertas_criados += 1
        
        conn.commit()
        logger.info(f"üîî {alertas_criados} alertas criados")
        
    except Exception as e:
        conn.rollback()
        logger.error(f"‚ùå Erro ao criar alertas: {e}")
    
    return alertas_criados


def registrar_log_consulta(
    conn: sqlite3.Connection,
    processo_id: int,
    workspace_id: int,
    numero_processo: str,
    tribunal_sigla: str,
    status: str,
    movimentacoes_encontradas: int,
    movimentacoes_novas: int,
    tempo_ms: int,
    erro: Optional[str] = None
) -> None:
    """
    Registra detalhes de cada consulta para auditoria e debugging
    
    üìä TABELA: datajud_consulta_logs
    
    Serve para:
    - Rastrear hist√≥rico de monitoramento
    - Identificar problemas com tribunais espec√≠ficos
    - Calcular estat√≠sticas de uso da API
    - Auditar atividades
    
    Args:
        conn: Conex√£o com banco
        processo_id: ID do processo
        workspace_id: ID do workspace
        numero_processo: NPU
        tribunal_sigla: Tribunal consultado
        status: 'sucesso', 'erro', 'vazio'
        movimentacoes_encontradas: Total encontradas
        movimentacoes_novas: Novas (inseridas)
        tempo_ms: Tempo de resposta
        erro: Mensagem de erro (se houver)
    """
    
    cursor = conn.cursor()
    
    try:
        cursor.execute('''
            INSERT INTO datajud_consulta_logs
            (workspace_id, processo_id, numero_processo, tribunal_sigla,
             endpoint_usado, status_consulta, movimentacoes_encontradas,
             movimentacoes_novas, tempo_resposta_ms, erro_msg, created_at)
            VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
        ''', (
            workspace_id,
            processo_id,
            numero_processo,
            tribunal_sigla,
            TRIBUNAIS_ENDPOINTS.get(tribunal_sigla, ''),
            status,
            movimentacoes_encontradas,
            movimentacoes_novas,
            tempo_ms,
            erro,
            datetime.now().strftime('%Y-%m-%d %H:%M:%S')
        ))
        
        conn.commit()
        
    except Exception as e:
        conn.rollback()
        logger.error(f"‚ùå Erro ao registrar log: {e}")


def processar_processo(
    processo_row: sqlite3.Row,
    conn: sqlite3.Connection
) -> Dict[str, Any]:
    """
    Processa um processo individual: consulta API, salva tudo, cria alertas
    
    üîÑ WORKFLOW:
    1. Extrai tribunal do n√∫mero (NPU parsing)
    2. Consulta API Datajud
    3. Se sucesso e encontrado:
       a. Salva movimenta√ß√µes (com INSERT OR IGNORE para duplicatas)
       b. Cria alertas para novas movimenta√ß√µes
       c. Atualiza data da √∫ltima verifica√ß√£o
    4. Registra log da consulta
    
    Args:
        processo_row: Row do SQLite com dados do processo
        conn: Conex√£o com banco
        
    Returns:
        Dict com resultado: sucesso, movimentacoes_novas, tempo_resposta_ms, etc
    """
    
    processo_id = processo_row['processo_id']
    numero_processo = processo_row['numero']
    workspace_id = processo_row['workspace_id']
    
    logger.info(f"‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ")
    logger.info(f"üìã Processando processo ID {processo_id}: {numero_processo}")
    logger.info(f"‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ")
    
    # ========================================================================
    # IDENTIFICA√á√ÉO DO TRIBUNAL (extrai automaticamente do NPU)
    # ========================================================================
    
    tribunal = extrair_tribunal_do_npu(numero_processo)
    
    if not tribunal:
        erro = "N√£o foi poss√≠vel identificar tribunal pelo n√∫mero do processo"
        logger.error(f"‚ùå {erro}")
        registrar_log_consulta(
            conn, processo_id, workspace_id, numero_processo,
            'DESCONHECIDO', 'erro', 0, 0, 0, erro
        )
        return {
            'sucesso': False,
            'erro': erro,
            'processo_id': processo_id
        }
    
    logger.info(f"üéØ Tribunal detectado: {tribunal}")
    
    # ========================================================================
    # DELAY ENTRE REQUISI√á√ïES (Rate Limiting)
    # ========================================================================
    
    time.sleep(DATAJUD_DELAY_ENTRE_REQUISICOES)
    
    # ========================================================================
    # CONSULTA √Ä API DATAJUD
    # ========================================================================
    
    resultado = consultar_processo_datajud(numero_processo, tribunal)
    
    if not resultado['sucesso']:
        # Consulta falhou
        registrar_log_consulta(
            conn, processo_id, workspace_id, numero_processo,
            tribunal, 'erro', 0, 0,
            resultado.get('tempo_resposta_ms', 0),
            resultado.get('erro', 'Erro desconhecido')
        )
        return resultado
    
    # Verificar se encontrou o processo
    if not resultado.get('encontrado', False):
        registrar_log_consulta(
            conn, processo_id, workspace_id, numero_processo,
            tribunal, 'vazio', 0, 0,
            resultado.get('tiempo_resposta_ms', 0),
            None
        )
        logger.info(f"‚ö†Ô∏è  Processo n√£o encontrado na API")
        return resultado
    
    # ========================================================================
    # SALVAMENTO DE MOVIMENTA√á√ïES
    # ========================================================================
    
    movimentos = resultado.get('movimentos', [])
    inseridas, duplicadas, novas_movimentacoes = salvar_movimentacoes(
        conn, processo_id, workspace_id, movimentos
    )
    
    # ========================================================================
    # CRIA√á√ÉO DE ALERTAS (Se houver novas movimenta√ß√µes)
    # ========================================================================
    
    alertas_criados = 0
    if novas_movimentacoes:
        alertas_criados = criar_alertas(
            conn, processo_id, workspace_id,
            numero_processo, novas_movimentacoes
        )
    
    # ========================================================================
    # ATUALIZA√á√ÉO DA DATA DE √öLTIMA VERIFICA√á√ÉO
    # ========================================================================
    
    try:
        cursor = conn.cursor()
        cursor.execute('''
            UPDATE processo_monitor_config
            SET ultima_verificacao = ?,
                total_movimentacoes = total_movimentacoes + ?
            WHERE processo_id = ?
        ''', (
            datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
            inseridas,
            processo_id
        ))
        conn.commit()
    except Exception as e:
        logger.error(f"‚ùå Erro ao atualizar config: {e}")
    
    # ========================================================================
    # REGISTRO DE LOG
    # ========================================================================
    
    registrar_log_consulta(
        conn, processo_id, workspace_id, numero_processo,
        tribunal, 'sucesso', len(movimentos), inseridas,
        resultado.get('tiempo_resposta_ms', 0), None
    )
    
    # ========================================================================
    # RETORNO COM ESTAT√çSTICAS
    # ========================================================================
    
    logger.info(f"‚úÖ Processamento completado!")
    
    return {
        'sucesso': True,
        'processo_id': processo_id,
        'numero_processo': numero_processo,
        'tribunal': tribunal,
        'movimentos_encontrados': len(movimentos),
        'movimentos_novos': inseridas,
        'movimentos_duplicados': duplicadas,
        'alertas_criados': alertas_criados,
        'tempo_resposta_ms': resultado.get('tiempo_resposta_ms', 0)
    }


# ============================================================================
# FUN√á√ÉO PRINCIPAL: EXECUTAR WORKER
# ============================================================================

def executar_monitoramento_datajud() -> Dict[str, Any]:
    """
    ü§ñ FUN√á√ÉO PRINCIPAL DO WORKER
    
    Executa o ciclo completo de monitoramento:
    1. Conecta ao banco de dados
    2. Busca processos marcados para monitoramento
    3. Processa cada um: API ‚Üí DB ‚Üí Alertas
    4. Retorna estat√≠sticas
    
    üí° INVOCA√á√ÉO:
    - Agendada via APScheduler (08:00 e 17:30)
    - E em app.py: scheduler.add_job(executar_monitoramento_datajud, ...)
    
    ‚ö° PERFORMANCE:
    - Execu√ß√£o: ~2-10 segundos por processo
    - N√£o bloqueia aplica√ß√£o principal
    - Logging detalhado para debugging
    - Rate limiting integrado
    
    Returns:
        Dict com:
        - sucesso: bool
        - timestamp: str
        - processos_processados: int
        - processos_com_atualizacoes: int
        - total_movimentacoes_novas: int
        - total_alertas_criados: int
        - erros: int
        - tempo_total_ms: int
    """
    
    import time
    tempo_inicio = time.time()
    
    logger.info("\n" + "="*70)
    logger.info("üöÄ INICIANDO MONITORAMENTO DATAJUD")
    logger.info(f"‚è∞ Timestamp: {datetime.now().strftime('%d/%m/%Y %H:%M:%S')}")
    logger.info("="*70)
    
    # ========================================================================
    # VALIDA√á√ÉO PR√â-EXECU√á√ÉO
    # ========================================================================
    
    if not DATAJUD_API_KEY:
        logger.error("‚ùå API Key n√£o configurada!")
        logger.error("Configure: export DATAJUD_API_KEY='sua_chave'")
        return {
            'sucesso': False,
            'erro': 'API Key n√£o configurada',
            'timestamp': datetime.now().isoformat()
        }
    
    # ========================================================================
    # CONEX√ÉO COM BANCO
    # ========================================================================
    
    try:
        conn = get_db_connection()
    except Exception as e:
        logger.error(f"‚ùå Erro ao conectar no banco: {e}")
        return {
            'sucesso': False,
            'erro': f'Erro de conex√£o: {e}',
            'timestamp': datetime.now().isoformat()
        }
    
    try:
        # ====================================================================
        # BUSCA PROCESSOS PARA MONITORAR
        # ====================================================================
        
        cursor = conn.cursor()
        
        # Busca processos onde:
        # - monitorar_datajud = 1 (marcado para monitorar)
        # - Ordena por √∫ltima verifica√ß√£o (mais antigas primeiro)
        
        cursor.execute('''
            SELECT 
                p.id as processo_id,
                p.numero,
                p.numero_cnj,
                p.workspace_id,
                pmc.ultima_verificacao
            FROM processos p
            LEFT JOIN processo_monitor_config pmc ON p.id = pmc.processo_id
            WHERE pmc.monitorar_datajud = 1
            ORDER BY pmc.ultima_verificacao ASC NULLS FIRST
        ''')
        
        processos = cursor.fetchall()
        
        if not processos:
            logger.warning("‚ö†Ô∏è  Nenhum processo marcado para monitoramento")
            return {
                'sucesso': True,
                'processos_processados': 0,
                'mensagem': 'Nenhum processo para monitorar',
                'timestamp': datetime.now().isoformat()
            }
        
        logger.info(f"üìã {len(processos)} processo(s) para processar")
        
        # ====================================================================
        # PROCESSAMENTO DE CADA PROCESSO
        # ====================================================================
        
        processos_com_atualizacoes = 0
        total_movimentacoes_novas = 0
        total_alertas_criados = 0
        erros = 0
        resultados = []
        
        for i, processo in enumerate(processos, 1):
            logger.info(f"\n[{i}/{len(processos)}] Processando...")
            
            resultado = processar_processo(processo, conn)
            
            if resultado['sucesso']:
                movimentos_novos = resultado.get('movimentos_novos', 0)
                if movimentos_novos > 0:
                    processos_com_atualizacoes += 1
                total_movimentacoes_novas += movimentos_novos
                total_alertas_criados += resultado.get('alertas_criados', 0)
            else:
                erros += 1
            
            resultados.append(resultado)
        
        # ====================================================================
        # RESUMO FINAL
        # ====================================================================
        
        tempo_total_ms = int((time.time() - tempo_inicio) * 1000)
        
        logger.info("\n" + "="*70)
        logger.info("üìä RESUMO DO MONITORAMENTO")
        logger.info("="*70)
        logger.info(f"‚úÖ Processos processados: {len(processos)}")
        logger.info(f"üîÑ Com atualiza√ß√µes: {processos_com_atualizacoes}")
        logger.info(f"üì® Movimenta√ß√µes novas: {total_movimentacoes_novas}")
        logger.info(f"üîî Alertas criados: {total_alertas_criados}")
        logger.info(f"‚ùå Erros: {erros}")
        logger.info(f"‚è±Ô∏è  Tempo total: {tempo_total_ms}ms ({tempo_total_ms/1000:.2f}s)")
        logger.info("="*70 + "\n")
        
        return {
            'sucesso': True,
            'timestamp': datetime.now().isoformat(),
            'processos_processados': len(processos),
            'processos_com_atualizacoes': processos_com_atualizacoes,
            'total_movimentacoes_novas': total_movimentacoes_novas,
            'total_alertas_criados': total_alertas_criados,
            'erros': erros,
            'tempo_total_ms': tempo_total_ms,
            'resultados_detalhados': resultados
        }
    
    except Exception as e:
        logger.exception(f"‚ùå Erro geral na execu√ß√£o: {e}")
        return {
            'sucesso': False,
            'erro': str(e),
            'timestamp': datetime.now().isoformat()
        }
    
    finally:
        conn.close()


# ============================================================================
# TESTE LOCAL
# ============================================================================

if __name__ == '__main__':
    """
    Script de teste local para validar o worker
    
    Uso:
        cd /caminho/para/juris/app
        export DATAJUD_API_KEY='sua_chave_aqui'
        python datajud_worker.py
    """
    
    resultado = executar_monitoramento_datajud()
    print("\n" + json.dumps(resultado, indent=2, ensure_ascii=False))
